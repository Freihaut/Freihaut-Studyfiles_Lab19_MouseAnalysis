{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Implementation of picture classification using fast ai</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### The code requires that the images are saved in a folder structure.\n",
    " For questions contact: paul.freihaut@psychologie.uni.freiburg.de\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import core modules\n",
    "from fastai.vision import *\n",
    "from fastai.metrics import accuracy\n",
    "import numpy as np\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Helper Function to create splitted datasets for cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split all participant data into 5 folds\n",
    "\n",
    "def create_cv_folds(path, namelen):\n",
    "    \n",
    "    fnames = get_image_files(path)\n",
    "    \n",
    "    print(fnames[0].stem)\n",
    "    \n",
    "    participant_ids = []\n",
    "\n",
    "    for file in fnames:\n",
    "        if file.stem[namelen:] not in participant_ids:\n",
    "            participant_ids.append(file.stem[namelen:])\n",
    "\n",
    "\n",
    "    # randomize particpant ids\n",
    "    shuffle(participant_ids)\n",
    "\n",
    "    folds = np.array_split(participant_ids, 5)\n",
    "    len(participant_ids)\n",
    "    print(folds[0])\n",
    "    return folds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use the images of the mouse usage data for condition classification using the fastai library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create a Image DataBunch containing the following steps:\n",
    "# 1. Where are the inputs and how to create them\n",
    "# 2. How to split the data into training and validation sets\n",
    "# 3. How to label the inputs\n",
    "# 4. What transforms to apply\n",
    "# 5. How to wrap in dataloaders and create the DataBunch\n",
    "\n",
    "# Classify the mouse usage pictures in the different tasks\n",
    "\n",
    "# folder refers to the name of the folder in which the images are stored, namelenght to the lenght of the image file names\n",
    "\n",
    "# Point Click task:\n",
    "folder, namelen = \"Images_PointClick_Task\", 14\n",
    "# Drag Drop task:\n",
    "# folder, namelen = \"Images_DragDrop_Task\", 12\n",
    "# Drawing task:\n",
    "# folder, namelen = \"Images_Drawing_Task\", 11\n",
    "# Follow- Box task:\n",
    "# folder, namelen = \"Images_FollowBox_Task\", 13\n",
    "\n",
    "print(folder + \" Classification using FastAI\")\n",
    "\n",
    "path = \"your_path/\" + folder\n",
    "\n",
    "\n",
    "# get the splits for the five-fold-cross-validation\n",
    "folds = create_cv_folds(path, namelen)\n",
    "\n",
    "\n",
    "# create a regular expression that grabs the correct data classes\n",
    "pat = r'/([^/]+)_\\d+.png$'\n",
    "\n",
    "# create a 5 fold-group validation loop\n",
    "\n",
    "for i in range(len(folds)):\n",
    "    \n",
    "    print(\"Using fold \" + str(i) + \" to validate and other folds to train\")\n",
    "    \n",
    "    # Create a databunch using the the validation set from the folds split\n",
    "    data = (ImageList.from_folder(path)\n",
    "            .split_by_valid_func(lambda o: o.stem[namelen:] in folds[i])\n",
    "            .label_from_re(pat)\n",
    "            .transform(size=224) # default 224\n",
    "            .databunch()\n",
    "            .normalize()\n",
    "    )\n",
    "\n",
    "    # Print the class names\n",
    "    print(data.classes)\n",
    "\n",
    "    # print information about the training and validation dataset\n",
    "    # print(data.dl)\n",
    "\n",
    "    # use this to show the images that are fed into the learner\n",
    "    # data.show_batch(rows=3, figsize=(7,6))\n",
    "    \n",
    "    # initiate the learner\n",
    "    learn = cnn_learner(data, models.resnet34, metrics=accuracy)\n",
    "    \n",
    "    # train and validate\n",
    "    learn.fit_one_cycle(3)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Save the results of the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PointClick:  48.888 2.224000000000001\n",
      "DragDrop:  52.5 4.330127018922194\n",
      "Drawing:  51.428 7.001866608269543\n",
      "FollowBox:  50.0 0.0\n",
      "LoadingTask: 56.907999999999994 5.13827364004682\n"
     ]
    }
   ],
   "source": [
    "# results from fastai analysis\n",
    "\n",
    "point_click = [50.00, 50.00, 44.44, 50.00, 50.00]\n",
    "print(\"PointClick: \", np.mean(point_click), np.std(point_click))\n",
    "drag_drop = [50.00, 60.00, 50.00, 50.00]\n",
    "print(\"DragDrop: \", np.mean(drag_drop), np.std(drag_drop))\n",
    "drawing = [50.00, 42.85, 50.00, 64.29, 50.00]\n",
    "print(\"Drawing: \", np.mean(drawing), np.std(drawing))\n",
    "follow_box = [50.00, 50.00, 50.00, 50.00, 50.00]\n",
    "print(\"FollowBox: \", np.mean(follow_box), np.std(follow_box))\n",
    "loading_task = [54.54, 50.00, 55.00, 60.00, 65.00]\n",
    "print(\"LoadingTask:\", np.mean(loading_task), np.std(loading_task))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:fastai]",
   "language": "python",
   "name": "conda-env-fastai-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}