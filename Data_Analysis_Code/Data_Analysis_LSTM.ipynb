{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9VOvtemBxXjO"
   },
   "outputs": [],
   "source": [
    "# core imports\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import interpolate\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Masking\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iZR-QMuIxt_2"
   },
   "outputs": [],
   "source": [
    "# the datasets are pickle files in the Data_LSTM_Analysis folder\n",
    "# get the relative path to the dataset\n",
    "fileDir = os.path.dirname(os.path.abspath(__file__))\n",
    "parentDir = os.path.dirname(fileDir)\n",
    "targetDir = os.path.join(parentDir, \"Datasets\", \"Data_LSTM_Analysis\")\n",
    "\n",
    "datapath = targetDir + \"/\"\n",
    "\n",
    "# open a saved dictionary\n",
    "def open_dict(name):\n",
    "    with open(datapath + name + \".pkl\", \"rb\") as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "68MgEHNOkIVk"
   },
   "source": [
    "<h2>Time Series Classification using a Long-Short-Term-Memory Neural Newtork</h2>\n",
    "<h3>Inspired by Blog Posts on https://machinelearningmastery.com/</h3>\n",
    "<p>More specifically:</p>\n",
    "<ul>\n",
    "<li>https://machinelearningmastery.com/sequence-classification-lstm-recurrent-neural-networks-python-keras/</li>\n",
    "<li>https://machinelearningmastery.com/reshape-input-data-long-short-term-memory-networks-keras/</li>\n",
    "<li>https://machinelearningmastery.com/prepare-univariate-time-series-data-long-short-term-memory-networks/</li>\n",
    "<li>https://machinelearningmastery.com/sequence-prediction/</li>\n",
    "</ul>\n",
    "\n",
    "\n",
    "<p>General Instruction to implement to LSTM for time-series classification using mouse usage data</p>\n",
    "\n",
    "* Interpolation of mouse movement data into equal timesteps\n",
    "* If applicable, seperate the mouse data into data per trial with overlaps at the beginning and end of a trial\n",
    "* Set the input lenght of to be between 200 and 400 data points (according to recommendations in the blog)\n",
    "* All trial datasets (or other subdatasets need to be of equal length, which requires trimming the datasets or filling the datastes with 0s)\n",
    "* Train a simple LSTM and test the prediction accuracy\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xthV06n8GEi9"
   },
   "outputs": [],
   "source": [
    "# Import the datasets\n",
    "\n",
    "pointclick_data = open_dict(\"Data_PointClick_Task\")\n",
    "dragdrop_data = open_dict(\"Data_DragDrop_Task\")\n",
    "followbox_data = open_dict(\"Data_Drawing_Task\")\n",
    "drawing_data = open_dict(\"Data_FollowBox_Task\")\n",
    "\n",
    "# data structure:\n",
    "# {participant: \n",
    "#   {high_stress: \n",
    "#     {circlesClicked: [...], eventtype[...], time: [...], x: [...], y: [...], DiffTime: [...]}, \n",
    "#    low_stress:\n",
    "#       {circlesClicked: [...], eventtype[...], time: [...], x: [...], y: [...], DiffTime: [...]}}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 127
    },
    "colab_type": "code",
    "id": "_NnEEzUQGMwT",
    "outputId": "3e24a0b3-f9e2-4bd8-a2dc-63eda4d42ea1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inBox\n",
      "eventType\n",
      "time\n",
      "x\n",
      "y\n",
      "DiffTime\n"
     ]
    }
   ],
   "source": [
    "# Playing around to understand the data\n",
    "\n",
    "for i in followbox_data:\n",
    "  for k in followbox_data[i]:\n",
    "    for l in followbox_data[i][k]:\n",
    "      print(l)\n",
    "    break\n",
    "  break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qhwBGk9EoaLt"
   },
   "source": [
    "<h3>Reusable functions</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vKUwNce6w3XK"
   },
   "outputs": [],
   "source": [
    "# interpolate the mouse data\n",
    "def interpolate_mouse_data(coordinate, time):\n",
    "\n",
    "    interp = interpolate.interp1d(time, coordinate)\n",
    "\n",
    "    # set start and end point of new timeline\n",
    "    start = time[0]\n",
    "    end = time[-1]\n",
    "\n",
    "    # create a new timeline array with equal timesteps using the start and endpoints\n",
    "    new_times = np.arange(start, end, 15)\n",
    "\n",
    "    # use the interpolation function to calculate the interpolated x- and y-coordinates on the equally spaced time\n",
    "    # interval \n",
    "    new_coord = np.round(interp(new_times), decimals=3)\n",
    "\n",
    "    # visualize the original vs the interpolated data)\n",
    "    # plt.plot(new_times, new_coord, linestyle=\"--\")\n",
    "    # plt.plot(time, coordinate, linestyle=\":\")\n",
    "    #\n",
    "    # plt.show()\n",
    "\n",
    "    return (new_coord, new_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GZqS_C4HMfEq"
   },
   "outputs": [],
   "source": [
    "# split a list into parts based on an indexlist\n",
    "# Splits the list WITH OVERLAP\n",
    "# useful for all tasks that have a \"trial structure\"\n",
    "def sep_list(separator, target_list):\n",
    "  \n",
    "  separated_list = []\n",
    "  \n",
    "  startpoint = 0\n",
    "  \n",
    "  for pos, ind in enumerate(separator):\n",
    "    \n",
    "    endpoint = startpoint + ind\n",
    "    \n",
    "    # splits the list based on the starting and end point plus 5 more datapoints\n",
    "    # if there are enough datapoints in the prev and following trial\n",
    "    \n",
    "    # the first trial can only have overlap with the next but not previous trial\n",
    "    if pos == 0:\n",
    "      len_next = 5 if separator[pos + 1] >= 5 else separator[pos + 1]\n",
    "      separated_list.append(target_list[startpoint:endpoint + len_next])\n",
    "    # the last trial can only have overlap with the previous but not next trial\n",
    "    elif pos == len(separator) - 1:\n",
    "      len_prev = 5 if separator[pos - 1] >= 5 else separator[pos - 1]\n",
    "      separated_list.append(target_list[startpoint - len_prev:endpoint])\n",
    "    else:\n",
    "      len_next = 5 if separator[pos + 1] >= 5 else separator[pos + 1]\n",
    "      len_prev = 5 if separator[pos - 1] >= 5 else separator[pos - 1]\n",
    "      separated_list.append(target_list[startpoint - len_prev:endpoint + len_next])\n",
    "      \n",
    "    startpoint = endpoint\n",
    "    \n",
    "  return separated_list\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HwBCd-lWFPK_"
   },
   "source": [
    "<h3>Point and Click Dataset Creation</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S_4YY1O6HbLY"
   },
   "outputs": [],
   "source": [
    "# group the Data of each participant into trials\n",
    "\n",
    "def create_point_click_data():\n",
    "\n",
    "  # Prepare observations/examples\n",
    "  input_series = []\n",
    "  output_classes = []\n",
    "  groups = []\n",
    "\n",
    "  bad_cases_point_click = [\"INFvFzlNN7UeZRqvtoe8hejtnvX2\",\n",
    "                              \"PRPyIVrPUVgCFtZ60nqvXc4wUov2\",\n",
    "                              \"Vhi1KMa2MecuTnTzWb8QBp9rNDw1\",\n",
    "                              \"X5mfB1vgISTp6cagPLnp0zyh4EI2\",\n",
    "                              \"ZnI96HDrRZV9xNlfQxgTU0CeoDX2\",\n",
    "                              \"zf3H80XYGSf9U3pZM5xxOm69qTT2\"]\n",
    "\n",
    "  # add emtpy dictionaries to bad cases (participant did not provide data)\n",
    "  for participant in pointclick_data:\n",
    "    if not pointclick_data[participant]:\n",
    "      bad_cases_point_click.append(participant)\n",
    "  \n",
    "  \n",
    "  # delete the bad cases from the dataset\n",
    "  for participant in bad_cases_point_click:\n",
    "    pointclick_data.pop(participant, None)\n",
    "\n",
    "# loop over the \"good data\"  \n",
    "for par_num, participant in enumerate(pointclick_data):\n",
    "    \n",
    "\n",
    "    # create a participant dummy variable to store information about the\n",
    "    # participant\n",
    "    par_dummy = [1 if i == par_num else 0 for i in range(len(pointclick_data))]\n",
    "    \n",
    "    # loop over the tasks conditions (high-stress or low-stress)\n",
    "    for task in pointclick_data[participant]:\n",
    "        \n",
    "        # save the task outcome\n",
    "        if \"HS\" in task:\n",
    "          output = 1\n",
    "        elif \"LS\" in task:\n",
    "          output = 0\n",
    "        \n",
    "        # normalize the x & y data using the screen width & height\n",
    "        x_coords = np.asarray(pointclick_data[participant][task][\"x\"]) / 1920\n",
    "        y_coords = np.asarray(pointclick_data[participant][task][\"y\"]) / 1080\n",
    "        \n",
    "        # separate the lists containing all data into a list with trial data\n",
    "        trial_separator = [len(list(y)) for x,y in itertools.groupby(pointclick_data[participant][task][\"circlesClicked\"])]\n",
    "        \n",
    "        sep_x = sep_list(trial_separator, x_coords)\n",
    "        sep_y = sep_list(trial_separator, y_coords)\n",
    "        sep_time = sep_list(trial_separator, pointclick_data[participant][task][\"DiffTime\"])\n",
    "        sep_eventType = sep_list(trial_separator, pointclick_data[participant][task][\"eventType\"])\n",
    "        \n",
    "        # interpolate x, y and time\n",
    "        \n",
    "        int_x = [interpolate_mouse_data(sep_x[i], sep_time[i])[0] for i in range(len(sep_x))]\n",
    "        int_y = [interpolate_mouse_data(sep_y[i], sep_time[i])[0] for i in range(len(sep_y))]\n",
    "        int_time = [interpolate_mouse_data(sep_y[i], sep_time[i])[1] for i in range(len(sep_y))]\n",
    "        \n",
    "        # create a list with the timings for a click event in a trial\n",
    "        all_clicktimes = []\n",
    "        # loop over the eventtype list\n",
    "        for i, trial in enumerate(sep_eventType):\n",
    "          trial_clickTimes = []\n",
    "          for k, event in enumerate(trial):\n",
    "            # if the eventtype is a mouseclick, save the corresponding timestamp\n",
    "            if event == \"MouseClick\":\n",
    "              trial_clickTimes.append(sep_time[i][k])\n",
    "          all_clicktimes.append(trial_clickTimes)\n",
    "              \n",
    "        # create a list with the indices in the interpolated lists that represent\n",
    "        # mouseclicks\n",
    "        click_index = []\n",
    "        # loop over all times in all trials\n",
    "        for ind, trial in enumerate(all_clicktimes):\n",
    "          trial_index = []\n",
    "          for clicktime in trial:\n",
    "            # find the first entry of the smallest difference between the original\n",
    "            # click timestamp and the timestamps in the interpolated list\n",
    "            click_ind = np.where(np.abs(clicktime - int_time[ind]) == np.ndarray.min(np.abs(clicktime - int_time[ind])))[0][0]\n",
    "            trial_index.append(click_ind)\n",
    "          click_index.append(trial_index)\n",
    "            \n",
    "        # create an event type list that stores information about the eventType\n",
    "        # of the interpolated datapoint\n",
    "        new_eventType = []\n",
    "        for num, trial in enumerate(click_index):\n",
    "          events = [0 if i in trial else 1 for i in range(len(int_time[num]))]\n",
    "          new_eventType.append(events)\n",
    "        \n",
    "        # add every trial as a feature to the input series list\n",
    "        for num in range(len(int_x)):\n",
    "          \n",
    "          # store all features in a list and also add the participant dummy\n",
    "          features = [int_x[num], int_y[num], new_eventType[num], par_dummy]\n",
    "          # append the features and the output per trial\n",
    "          input_series.append(features)\n",
    "          output_classes.append(output)\n",
    "          groups.append(par_num)\n",
    "    \n",
    "  return input_series, output_classes, groups\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zWnsojIeAu0m"
   },
   "source": [
    "<h3>Drag and Drop Task Dataset Creation</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uEIBdzcoA1aq"
   },
   "outputs": [],
   "source": [
    "# group the Data of each participant into trials\n",
    "\n",
    "def create_drag_drop_data():\n",
    "\n",
    "  # Prepare observations/examples\n",
    "  input_series = []\n",
    "  output_classes = []\n",
    "  groups = []\n",
    "\n",
    "  bad_cases_drag_drop = [\n",
    "         \"Vhi1KMa2MecuTnTzWb8QBp9rNDw1\",\n",
    "        \"ZnI96HDrRZV9xNlfQxgTU0CeoDX2\",\n",
    "        \"dOXefJ4hHEfRsYTTFfn6NfATnh32\"]\n",
    "\n",
    "  # add emtpy dictionaries to bad cases (participant did not provide data)\n",
    "  for participant in dragdrop_data:\n",
    "    if not dragdrop_data[participant]:\n",
    "      bad_cases_drag_drop.append(participant)\n",
    "\n",
    "  # delete the bad cases from the dataset\n",
    "  for participant in bad_cases_drag_drop:\n",
    "    dragdrop_data.pop(participant, None)\n",
    "\n",
    "  # information about drag and drop task\n",
    "  for par_num, participant in enumerate(dragdrop_data):\n",
    "    \n",
    "\n",
    "    # create a participant dummy variable\n",
    "    par_dummy = [1 if i == par_num else 0 for i in range(len(dragdrop_data))]\n",
    "    \n",
    "    # loop over the tasks conditions (high-stress or low-stress)\n",
    "    for task in dragdrop_data[participant]:\n",
    "        \n",
    "        # save the task outcome\n",
    "        if \"HS\" in task:\n",
    "          output = 1\n",
    "        elif \"LS\" in task:\n",
    "          output = 0\n",
    "        \n",
    "        # normalize the x & y data using the screen width & height\n",
    "        x_coords = np.asarray(dragdrop_data[participant][task][\"x\"]) / 1920\n",
    "        y_coords = np.asarray(dragdrop_data[participant][task][\"y\"]) / 1080\n",
    "        \n",
    "        # separate the lists containing all data into a list with trial data\n",
    "        trial_separator = [len(list(y)) for x,y in itertools.groupby(dragdrop_data[participant][task][\"circlesDragged\"])]\n",
    "        \n",
    "        sep_x = sep_list(trial_separator, x_coords)\n",
    "        sep_y = sep_list(trial_separator, y_coords)\n",
    "        sep_time = sep_list(trial_separator, dragdrop_data[participant][task][\"DiffTime\"])\n",
    "        sep_eventType = sep_list(trial_separator, dragdrop_data[participant][task][\"eventType\"])\n",
    "        \n",
    "        # interpolate x, y and time\n",
    "        \n",
    "        int_x = [interpolate_mouse_data(sep_x[i], sep_time[i])[0] for i in range(len(sep_x))]\n",
    "        int_y = [interpolate_mouse_data(sep_y[i], sep_time[i])[0] for i in range(len(sep_y))]\n",
    "        int_time = [interpolate_mouse_data(sep_y[i], sep_time[i])[1] for i in range(len(sep_y))]\n",
    "        \n",
    "        # create a list with the timings for a click event in a trial\n",
    "        all_clicktimes = []\n",
    "        # loop over the eventtype list\n",
    "        for i, trial in enumerate(sep_eventType):\n",
    "          trial_clickTimes = []\n",
    "          for k, event in enumerate(trial):\n",
    "            # if the eventtype is a mouseclick, save the corresponding timestamp\n",
    "            if event == \"MouseClick\":\n",
    "              trial_clickTimes.append(sep_time[i][k])\n",
    "          all_clicktimes.append(trial_clickTimes)\n",
    "              \n",
    "        # create a list with the indices in the interpolated lists that represent\n",
    "        # mouseclicks\n",
    "        click_index = []\n",
    "        # loop over all times in all trials\n",
    "        for ind, trial in enumerate(all_clicktimes):\n",
    "          trial_index = []\n",
    "          for clicktime in trial:\n",
    "            # find the first entry of the smallest difference between the original\n",
    "            # click timestamp and the timestamps in the interpolated list\n",
    "            click_ind = np.where(np.abs(clicktime - int_time[ind]) == np.ndarray.min(np.abs(clicktime - int_time[ind])))[0][0]\n",
    "            trial_index.append(click_ind)\n",
    "          click_index.append(trial_index)\n",
    "            \n",
    "        # create an event type list that stores information about the eventType\n",
    "        # of the interpolated datapoint\n",
    "        new_eventType = []\n",
    "        for num, trial in enumerate(click_index):\n",
    "          events = [0 if i in trial else 1 for i in range(len(int_time[num]))]\n",
    "          new_eventType.append(events)\n",
    "        \n",
    "         # add every trial as a feature to the input series list\n",
    "        for num in range(len(int_x)):\n",
    "          \n",
    "          # store all features in a list and also add the participant dummy\n",
    "          features = [int_x[num], int_y[num], new_eventType[num], par_dummy]\n",
    "          # append the features and the output per trial\n",
    "          input_series.append(features)\n",
    "          output_classes.append(output)\n",
    "          groups.append(par_num)\n",
    "    \n",
    "  return input_series, output_classes, groups\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FEfttqwtmrk9"
   },
   "source": [
    "<h3>Drawing Task Dataset Creation</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5IJBNjsjmAr3"
   },
   "outputs": [],
   "source": [
    "# group the Data of each participant into trials\n",
    "\n",
    "def create_drawing_data():\n",
    "\n",
    "  # Prepare observations/examples\n",
    "  input_series = []\n",
    "  output_classes = []\n",
    "  groups = []\n",
    "\n",
    "  bad_cases_drawing = [\n",
    "         \"4ibZh6HiVrPknUuvasf6CIVD1L42\",\n",
    "        \"9DdqeM3mkRWvD4MCMcWvFH4wIhA2\",\n",
    "        \"GzlieWRWOJgquA0nDZtBFExSW0E2\",\n",
    "        \"PRPyIVrPUVgCFtZ60nqvXc4wUov2\",\n",
    "        \"V6TlsMC21YbLX2MyjUiEiVrhgMk2\",\n",
    "        \"Vhi1KMa2MecuTnTzWb8QBp9rNDw1\",\n",
    "        \"WpwRDjuqqdRavEdFOgqbpRA19Q32\",\n",
    "        \"b8KoZn71FhOsv46MKFAlqdhTBXM2\",\n",
    "        \"bD83eNrrWTgjMkVAdibgZNiebTe2\",\n",
    "        \"cgS7wdlEL3XTYUiBbXGDGCoyJWe2\",\n",
    "        \"dOXefJ4hHEfRsYTTFfn6NfATnh32\",\n",
    "        \"gJnYNGrs0lhMSKDh9i466E2MiJn2\",\n",
    "        \"nDsahKaZCEUMI732rmmyANfauCj1\",\n",
    "        \"nQl80EJnrxYnsuoVqEFhTMzZVgl2\",\n",
    "        \"pPx9EQjAJuN5wxinUZjO6DUsZDo1\",\n",
    "        \"uQ5ly8q3nPQZHi56WJFlw0Y3A4E2\",\n",
    "        \"zoCupEvJwahE0hRlqKWLyP8TRrJ2\"]\n",
    "\n",
    "  # add emtpy dictionaries to bad cases (participant did not provide data)\n",
    "  for participant in drawing_data:\n",
    "    if not drawing_data[participant]:\n",
    "      bad_cases_drawing.append(participant)\n",
    "\n",
    "  # delete the bad cases from the dataset\n",
    "  for participant in bad_cases_drawing:\n",
    "    drawing_data.pop(participant, None)\n",
    "\n",
    "  # information about drag and drop task\n",
    "  for par_num, participant in enumerate(drawing_data):\n",
    "    \n",
    "\n",
    "    # create a participant dummy variable\n",
    "    par_dummy = [1 if i == par_num else 0 for i in range(len(drawing_data))]\n",
    "    \n",
    "\n",
    "    for task in drawing_data[participant]:\n",
    "        \n",
    "        # save the task outcome\n",
    "        if \"HS\" in task:\n",
    "          output = 1\n",
    "        elif \"LS\" in task:\n",
    "          output = 0\n",
    "        \n",
    "        # normalize the x & y data using the screen width & height\n",
    "        x_coords = np.asarray(drawing_data[participant][task][\"x\"]) / 1920\n",
    "        y_coords = np.asarray(drawing_data[participant][task][\"y\"]) / 1080\n",
    "        \n",
    "        # separate the lists containing all data into a list with trial data\n",
    "        trial_separator = [len(list(y)) for x,y in itertools.groupby(drawing_data[participant][task][\"touchedMilestones\"])]\n",
    "        \n",
    "        sep_x = sep_list(trial_separator, x_coords)\n",
    "        sep_y = sep_list(trial_separator, y_coords)\n",
    "        sep_time = sep_list(trial_separator, drawing_data[participant][task][\"DiffTime\"])\n",
    "        sep_eventType = sep_list(trial_separator, drawing_data[participant][task][\"eventType\"])\n",
    "        \n",
    "        # interpolate x, y and time\n",
    "        \n",
    "        int_x = [interpolate_mouse_data(sep_x[i], sep_time[i])[0] for i in range(len(sep_x))]\n",
    "        int_y = [interpolate_mouse_data(sep_y[i], sep_time[i])[0] for i in range(len(sep_y))]\n",
    "        int_time = [interpolate_mouse_data(sep_y[i], sep_time[i])[1] for i in range(len(sep_y))]\n",
    "        \n",
    "        # create a list with the timings for a click event in a trial\n",
    "        all_clicktimes = []\n",
    "        # loop over the eventtype list\n",
    "        for i, trial in enumerate(sep_eventType):\n",
    "          trial_clickTimes = []\n",
    "          for k, event in enumerate(trial):\n",
    "            # if the eventtype is a mouseclick, save the corresponding timestamp\n",
    "            if event == \"MouseClick\":\n",
    "              trial_clickTimes.append(sep_time[i][k])\n",
    "          all_clicktimes.append(trial_clickTimes)\n",
    "              \n",
    "        # create a list with the indices in the interpolated lists that represent\n",
    "        # mouseclicks\n",
    "        click_index = []\n",
    "        # loop over all times in all trials\n",
    "        for ind, trial in enumerate(all_clicktimes):\n",
    "          trial_index = []\n",
    "          for clicktime in trial:\n",
    "            # find the first entry of the smallest difference between the original\n",
    "            # click timestamp and the timestamps in the interpolated list\n",
    "            click_ind = np.where(np.abs(clicktime - int_time[ind]) == np.ndarray.min(np.abs(clicktime - int_time[ind])))[0][0]\n",
    "            trial_index.append(click_ind)\n",
    "          click_index.append(trial_index)\n",
    "\n",
    "        # create an event type list that stores information about the eventType\n",
    "        # of the interpolated datapoint\n",
    "        new_eventType = []\n",
    "        for num, trial in enumerate(click_index):\n",
    "          events = [0 if i in trial else 1 for i in range(len(int_time[num]))]\n",
    "          new_eventType.append(events)\n",
    "        \n",
    "         # add every trial as a feature to the input series list\n",
    "        for num in range(len(int_x)):\n",
    "          \n",
    "          # store all features in a list and also add the participant dummy\n",
    "          features = [int_x[num], int_y[num], new_eventType[num], par_dummy]\n",
    "          # append the features and the output per trial\n",
    "          input_series.append(features)\n",
    "          output_classes.append(output)\n",
    "          groups.append(par_num)\n",
    "    \n",
    "  return input_series, output_classes, groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jKVFutJBgw0Z"
   },
   "source": [
    "<h3>Follow-Box Dataset Creation</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y0i9i1rGg2F2"
   },
   "outputs": [],
   "source": [
    "# group the Data of each participant into trials\n",
    "\n",
    "def create_follow_box_data():\n",
    "\n",
    "  # Prepare observations/examples\n",
    "  input_series = []\n",
    "  output_classes = []\n",
    "  groups = []\n",
    "\n",
    "  bad_cases_box = [\n",
    "        ]\n",
    "\n",
    "  # add emtpy dictionaries to bad cases (participant did not provide data)\n",
    "  for participant in followbox_data:\n",
    "    if not followbox_data[participant]:\n",
    "      bad_cases_box.append(participant)\n",
    "\n",
    "  # delete the bad cases from the dataset\n",
    "  for participant in bad_cases_box:\n",
    "    followbox_data.pop(participant, None)\n",
    "\n",
    "  # information about drag and drop task\n",
    "  for par_num, participant in enumerate(followbox_data):\n",
    "    \n",
    "\n",
    "    # create a participant dummy variable\n",
    "    par_dummy = [1 if i == par_num else 0 for i in range(len(followbox_data))]\n",
    "    \n",
    "\n",
    "    for task in followbox_data[participant]:\n",
    "        \n",
    "        # save the task outcome\n",
    "        if \"HS\" in task:\n",
    "          output = 1\n",
    "        elif \"LS\" in task:\n",
    "          output = 0\n",
    "        \n",
    "        # normalize the x & y data using the screen width & height\n",
    "        x_coords = np.asarray(followbox_data[participant][task][\"x\"]) / 1920\n",
    "        y_coords = np.asarray(followbox_data[participant][task][\"y\"]) / 1080\n",
    "        \n",
    "        # the follow box task cant be split by trials but has too many\n",
    "        # datapoints --> the dataset is split into ruffly 5 equal parts\n",
    "        sep_x = np.array_split(x_coords, 5)\n",
    "        sep_y = np.array_split(y_coords, 5)\n",
    "        sep_time = np.array_split(followbox_data[participant][task][\"DiffTime\"], 5)\n",
    "        sep_eventType = np.array_split(followbox_data[participant][task][\"eventType\"], 5)\n",
    "        \n",
    "        # interpolate x, y and time\n",
    "        \n",
    "        int_x = [interpolate_mouse_data(sep_x[i], sep_time[i])[0] for i in range(len(sep_x))]\n",
    "        int_y = [interpolate_mouse_data(sep_y[i], sep_time[i])[0] for i in range(len(sep_y))]\n",
    "        int_time = [interpolate_mouse_data(sep_y[i], sep_time[i])[1] for i in range(len(sep_y))]\n",
    "        \n",
    "       # create a list with the timings for a click event in a trial\n",
    "        all_clicktimes = []\n",
    "        # loop over the eventtype list\n",
    "        for i, trial in enumerate(sep_eventType):\n",
    "          trial_clickTimes = []\n",
    "          for k, event in enumerate(trial):\n",
    "            # if the eventtype is a mouseclick, save the corresponding timestamp\n",
    "            if event == \"MouseClick\":\n",
    "              trial_clickTimes.append(sep_time[i][k])\n",
    "          all_clicktimes.append(trial_clickTimes)\n",
    "              \n",
    "       # create a list with the indices in the interpolated lists that represent\n",
    "        # mouseclicks\n",
    "        click_index = []\n",
    "        # loop over all times in all trials\n",
    "        for ind, trial in enumerate(all_clicktimes):\n",
    "          trial_index = []\n",
    "          for clicktime in trial:\n",
    "            # find the first entry of the smallest difference between the original\n",
    "            # click timestamp and the timestamps in the interpolated list\n",
    "            click_ind = np.where(np.abs(clicktime - int_time[ind]) == np.ndarray.min(np.abs(clicktime - int_time[ind])))[0][0]\n",
    "            trial_index.append(click_ind)\n",
    "          click_index.append(trial_index)\n",
    "            \n",
    "        # create an event type list that stores information about the eventType\n",
    "        # of the interpolated datapoint\n",
    "        new_eventType = []\n",
    "        for num, trial in enumerate(click_index):\n",
    "          events = [0 if i in trial else 1 for i in range(len(int_time[num]))]\n",
    "          new_eventType.append(events)\n",
    "                \n",
    "        # add every trial as a feature to the input series list\n",
    "        for num in range(len(int_x)):  \n",
    "          # store all features in a list and also add the participant dummy\n",
    "          features = [int_x[num], int_y[num], new_eventType[num], par_dummy]\n",
    "          # append the features and the output per trial\n",
    "          input_series.append(features)\n",
    "          output_classes.append(output)\n",
    "          groups.append(par_num)\n",
    "\n",
    "  return input_series, output_classes, groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zuocqq8VsVcF"
   },
   "source": [
    "<h3>Create the relevant dataset to use it for classification in the next steps</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dp5S0FPgqFvl"
   },
   "outputs": [],
   "source": [
    "# get the relevant dataset (function names):\n",
    "# create_point_click_data()\n",
    "# create_drag_drop_data()\n",
    "# create_drawing_data()\n",
    "# create_follow_box_data()\n",
    "\n",
    "# the following steps are the same for all tasks (here the follow_box_task analysis is chosen)\n",
    "input_series, output_classes, groups = create_follow_box_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z3mwX_2BS2-J"
   },
   "outputs": [],
   "source": [
    "# resample input series into equal sample size based padding and truncating\n",
    "\n",
    "# takes a list and a certain length as an input and returns a list of the\n",
    "# specified length. If the length of the original list is longer than the\n",
    "# specified list, the original list ist cut to the specified list. If the\n",
    "# original list is shorter, the list is filled with 0s until the desired length\n",
    "\n",
    "def trp(item_list, length, filler):\n",
    "  if length > len(item_list):\n",
    "    return np.append(item_list[:length], [filler]*(length-len(item_list)), axis=0)\n",
    "  else:\n",
    "    return np.asarray(item_list)\n",
    "\n",
    "# get the longest size of the task trials\n",
    "size = np.max([len(i[0]) for i in input_series])\n",
    "\n",
    "resampled_input = []\n",
    "\n",
    "# resample all other trials to be the same lenght\n",
    "for trial_input in input_series:\n",
    "  \n",
    "  trial_list = []\n",
    "  \n",
    "  # resample the input features to match the longest input feature array\n",
    "  resampled_x = trp(trial_input[0], size, -1)\n",
    "  resampled_y = trp(trial_input[1], size, -1)\n",
    "  resampled_event = trp(trial_input[2], size, -1)\n",
    "  # add x, y and event to resampled trial list\n",
    "  trial_list.extend([resampled_x, resampled_y, resampled_event])\n",
    "  \n",
    "  # get participant info data (one-hot-encoded) and seperate it into the same\n",
    "  # data format as x, y and events and add to resampled trial list\n",
    "  for i in trial_input[3]:\n",
    "    trial_list.append([i] * size)\n",
    "  \n",
    "  resampled_input.append(trial_list)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "IJCYdmD5iQso",
    "outputId": "f40d1de1-e515-4be4-daed-f144a96274c5"
   },
   "outputs": [],
   "source": [
    "#  get some information about the input characteristics (check to see if everything works)\n",
    "samples = len(resampled_input)\n",
    "feature_count = len(resampled_input[0])\n",
    "timesteps = len(resampled_input[0][0])\n",
    "\n",
    "X = np.array(resampled_input).reshape((samples, timesteps, feature_count))\n",
    "\n",
    "\n",
    "print(samples, feature_count, timesteps)\n",
    "# print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use the resampled dataset for LSTM classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "_bqH5lG2rz6H",
    "outputId": "ab09a9db-a8aa-4c44-c252-df6697416ce6"
   },
   "outputs": [],
   "source": [
    "# Classification with equal sample length\n",
    "#----------------------------------------\n",
    "\n",
    "# Input characteristics\n",
    "samples = len(resampled_input)\n",
    "feature_count = len(resampled_input[0])\n",
    "timesteps = len(resampled_input[0][0])\n",
    "\n",
    "kfold = GroupKFold(n_splits=5)\n",
    "\n",
    "# Prepare input and output arrays\n",
    "X = np.array(resampled_input).reshape((samples, timesteps, feature_count))\n",
    "y = np.array(output_classes)\n",
    "\n",
    "# do 5-fold cross validation\n",
    "for train, test in kfold.split(X, y, groups=groups):\n",
    "\n",
    "  print(\"Classification in a CV fold\")\n",
    "  \n",
    "  X_train, X_test = X[train], X[test]\n",
    "  y_train, y_test = y[train], y[test]\n",
    "  \n",
    "  \n",
    "  print(\"-------Shapes-------\")\n",
    "  print(X_train.shape, X_test.shape)\n",
    "\n",
    "\n",
    "  # Define LSTM model\n",
    "  model = Sequential()\n",
    "  model.add(Masking(mask_value=0., input_shape=(timesteps, feature_count)))\n",
    "  model.add(LSTM(32, dropout=0.2, return_sequences=False, input_shape=(timesteps, feature_count)))\n",
    "  model.add(Dense(1, activation='sigmoid'))\n",
    "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "  # print(model.summary())\n",
    "\n",
    "  # Train\n",
    "  history = model.fit(X_train, y_train, epochs=5, batch_size=64)\n",
    "\n",
    "  # Evaluate\n",
    "  scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "  print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n",
    "  \n",
    "  # plt.plot(history.history[\"loss\"])\n",
    "  # plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Store the results of the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 109
    },
    "colab_type": "code",
    "id": "oiWcpOyzdl6Y",
    "outputId": "868b0c0e-7f9f-4148-fc11-9afab88c0468"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PointClick 50.0 0.0\n",
      "Loading 56.910000000000004 4.048752894410821\n",
      "DragDrop 50.0 0.0\n",
      "Drawing 50.0 0.0\n",
      "FollowBox 50.2 1.511608414901161\n"
     ]
    }
   ],
   "source": [
    "# results:\n",
    "point_click_results = [50.00, 50.00, 50.00, 50.00, 50.00]\n",
    "print(\"PointClick\", np.mean(point_click_results), np.std(point_click_results))\n",
    "results_loading = [54.55, 60.00, 60.00, 50.00, 60.00]\n",
    "print(\"Loading\", np.mean(results_loading), np.std(results_loading))\n",
    "results_dragdrop = [50.00, 50.00, 50.00, 50.00, 50.00]\n",
    "print(\"DragDrop\", np.mean(results_dragdrop), np.std(results_dragdrop))\n",
    "results_drawing = [50.00, 50.00, 50.00, 50.00, 50.00]\n",
    "print(\"Drawing\", np.mean(results_drawing), np.std(results_drawing))\n",
    "results_followBox = [51.82, 48.18, 50.00, 52.00, 49.00]\n",
    "print(\"FollowBox\", np.mean(results_followBox), np.std(results_followBox))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Raw_Data_Analysis.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}